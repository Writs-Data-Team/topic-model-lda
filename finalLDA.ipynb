{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb672aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final topic model for SCOTUS petitions with topic assignment and distribution graph\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import re\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaMulticore, CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import pyarrow as pa\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "base_stop = set(stopwords.words('english'))\n",
    "\n",
    "#mega jargon list\n",
    "legal_stop = {\n",
    "\n",
    "    # Parties and legal actors\n",
    "    \"court\", \"judge\", \"justice\", \"plaintiff\", \"defendant\", \"appellant\", \"appellee\",\n",
    "    \"respondent\", \"petitioner\", \"prosecutor\", \"defense\", \"counsel\", \"attorney\", \"attorneys\",\n",
    "    \"lawyer\", \"firm\", \"litigant\", \"party\", \"parties\", \"represent\", \"representation\",\n",
    "\n",
    "    # Legal process and documents\n",
    "    \"petition\", \"brief\", \"writ\", \"writs\", \"opinion\", \"decision\", \"dissent\", \"concurrence\",\n",
    "    \"judgment\", \"order\", \"motion\", \"motions\", \"plea\", \"pleaded\", \"pleading\", \"filing\",\n",
    "    \"filed\", \"record\", \"docket\", \"summary\", \"memorandum\", \"transcript\", \"statement\", \"testimony\",\n",
    "    \"exhibit\", \"appendix\", \"page\", \"pages\", \"volume\", \"footnote\", \"note\", \"citation\", \"citations\",\n",
    "\n",
    "    # Court actions and outcomes\n",
    "    \"certiorari\", \"remand\", \"dismiss\", \"affirm\", \"reverse\", \"vacate\", \"rehearing\", \"injunction\",\n",
    "    \"sentence\", \"sentencing\", \"verdict\", \"arraignment\", \"indictment\", \"conviction\", \"acquittal\",\n",
    "    \"retrial\", \"mistrial\", \"stay\", \"reversal\", \"hearing\", \"trial\", \"review\", \"jurisdiction\",\n",
    "\n",
    "    # Legal theory, reasoning, and doctrines\n",
    "    \"holding\", \"dicta\", \"precedent\", \"jurisprudence\", \"standard\", \"burden\", \"test\", \"mens\",\n",
    "    \"rea\", \"actus\", \"reus\", \"prima\", \"facie\", \"res\", \"judicata\", \"stare\", \"decisis\", \"ratio\",\n",
    "    \"obiter\", \"legal\", \"illegal\", \"unlawful\", \"liability\", \"negligence\", \"tort\", \"contract\",\n",
    "    \"damages\", \"injury\", \"harm\", \"equity\", \"remedy\", \"estoppel\", \"waiver\", \"doctrine\",\n",
    "\n",
    "    # Legal language and Latin phrases\n",
    "    \"habeas\", \"corpus\", \"ex\", \"parte\", \"en\", \"banc\", \"voir\", \"dire\", \"nolo\", \"contendere\",\n",
    "    \"amicus\", \"curiae\", \"per\", \"curiam\", \"de\", \"facto\", \"de\", \"jure\", \"inter\", \"alia\", \"ipso\", \"facto\",\n",
    "    \"ultra\", \"vires\", \"sine\", \"qua\", \"non\", \"pro\", \"se\", \"in\", \"re\", \"sub\", \"judice\",\n",
    "\n",
    "    # Legal categories and law types\n",
    "    \"civil\", \"criminal\", \"statutory\", \"common\", \"constitutional\", \"federal\", \"state\", \"administrative\",\n",
    "    \"tax\", \"property\", \"procedural\", \"substantive\", \"corporate\", \"securities\", \"antitrust\", \"employment\",\n",
    "\n",
    "    # Institutions and courts\n",
    "    \"supreme\", \"circuit\", \"district\", \"appeals\", \"tribunal\", \"agency\", \"commission\", \"board\",\n",
    "    \"department\", \"bureau\", \"office\", \"government\", \"federal\", \"municipal\", \"state\", \"official\", \"officials\",\n",
    "\n",
    "    # Legal structure terms\n",
    "    \"act\", \"acts\", \"statute\", \"statutes\", \"clause\", \"clauses\", \"section\", \"sections\", \"subsection\", \"article\",\n",
    "    \"regulation\", \"regulations\", \"rule\", \"rules\", \"code\", \"ordinance\", \"title\", \"chapter\", \"paragraph\",\n",
    "\n",
    "    # Time and reference noise\n",
    "    \"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\",\n",
    "    \"october\", \"november\", \"december\", \"year\", \"date\", \"number\", \"volume\", \"page\", \"pages\",\n",
    "\n",
    "    # Corporate/legal entity suffixes\n",
    "    \"inc\", \"corp\", \"llc\", \"ltd\", \"company\", \"co\", \"group\", \"pllc\", \"plc\", \"pc\", \"partners\", \"lp\", \"llp\",\n",
    "\n",
    "    # Legal publication and citation shorthand\n",
    "    \"us\", \"l\", \"ed\", \"sup\", \"ct\", \"fed\", \"f\", \"2d\", \"3d\", \"cir\", \"so\", \"cal\", \"ny\", \"mass\",\n",
    "    \"ill\", \"tex\", \"wash\", \"ala\", \"nc\", \"ga\", \"fl\", \"ariz\", \"ohio\", \"mich\", \"tenn\", \"mo\", \"kan\",\n",
    "\n",
    "    # Miscellaneous stop words in legal discourse\n",
    "    \"herein\", \"thereof\", \"hereto\", \"therein\", \"hereby\", \"whereas\", \"wherein\", \"thereby\",\n",
    "    \"hereafter\", \"thereafter\", \"thereunder\", \"hereunder\", \"american\", \"subject\", \"matter\",\n",
    "\n",
    "    # Redundancies / common SCOTUS metadata\n",
    "    \"et\", \"al\", \"vs\", \"v\", \"united\", \"states\", \"government\", \"state\", \"people\", \"county\", \"city\",\n",
    "    \"district\", \"school\", \"board\", \"department\", \"commission\", \"office\",\n",
    "\n",
    "    # Cleaning artifacts / OCR or text error tokens\n",
    "    \"cee\", \"cece\", \"een\", \"supp\", \"title\", \"cir\", \"inc\", \"fed\", \"corp\"\n",
    "\n",
    "    #miscellaneous stop words after runs\n",
    "    \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\", \n",
    "    \"cause\",\"allege\", \"must\", \"york\", \"tell\", \"get\", \"word\", \"supra\", \"see\", \"call\",\n",
    "     \"must\", \"apply\", \"decide\", \"determine\", \"result\", \"effect\",\n",
    "    \"know\", \"tell\", \"get\", \"offer\", \"ask\", \"call\",\n",
    "    \"plan\", \"system\", \"mean\", \"language\", \"word\", \"report\",\n",
    "    \"york\", \"texas\", \"california\", \"washington\", \"america\", \"john\",\n",
    "    \"work\", \"officer\", \"agent\", \"whether\", \"within\", \"action\", \"relief\", \"set\", \"even\", \"new\", \"respect\", \"show\",\n",
    "    \"fully\", \"since\", \"sec\", \"committee\", \"house\", \"cong\", \"cong_sess\", \"app\",\n",
    "    \"hawaiian\", \"palmyra\", \"wilkinson\", \"bent\", \"king\"\n",
    "\n",
    "}\n",
    "\n",
    "stop_words = base_stop | legal_stop\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])\n",
    "\n",
    "def clean_boilerplate(text):\n",
    "    text = re.sub(r\"No\\\\.\\\\s*\\\\d{1,6}(?:[-–]\\\\d{1,6})?\", \"\", text)\n",
    "    text = re.sub(r\"U\\\\.?S\\\\.?\\\\s*\\\\d+\", \"\", text)\n",
    "    text = re.sub(r\"(?si)^.*?(JOINT\\\\s+PETITION\\\\s+FOR\\\\s+A\\\\s+WRIT\\\\s+OF\\\\s+CERTIORARI)\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def preprocess(text, min_len=3):\n",
    "    t = clean_boilerplate(text)\n",
    "    t = re.sub(r\"[^A-Za-z]\", \" \", t).lower()\n",
    "    toks = simple_preprocess(t, deacc=True, min_len=min_len)\n",
    "    toks = [w for w in toks if w not in stop_words]\n",
    "    doc = nlp(\" \".join(toks))\n",
    "    return [tok.lemma_ for tok in doc if tok.lemma_ not in stop_words]\n",
    "\n",
    "def stream_parquet_docs(path, column='text', batch_size=10000, min_words=100):\n",
    "    pf = pq.ParquetFile(path)\n",
    "    for batch in pf.iter_batches(batch_size=batch_size):\n",
    "        df = batch.to_pandas()\n",
    "        for txt in df[column].dropna().astype(str):\n",
    "            buf, count = [], 0\n",
    "            for w in txt.split():\n",
    "                buf.append(w); count += 1\n",
    "                if count >= min_words:\n",
    "                    yield \" \".join(buf)\n",
    "                    buf, count = [], 0\n",
    "            if buf:\n",
    "                yield \" \".join(buf)\n",
    "\n",
    "PARQUET_PATH = \"data/raw_petitions_text.parquet\"\n",
    "TEXT_COL     = \"text\"\n",
    "documents, text_data = [], []\n",
    "\n",
    "pf = pq.ParquetFile(PARQUET_PATH)\n",
    "total_rows = sum(batch.num_rows for batch in pf.iter_batches())\n",
    "\n",
    "for chunk in tqdm(stream_parquet_docs(PARQUET_PATH, column=TEXT_COL), total=total_rows):\n",
    "    toks = preprocess(chunk)\n",
    "    if len(toks) >= 5:\n",
    "        documents.append(toks)\n",
    "        text_data.append(chunk)\n",
    "\n",
    "print(f\"Collected {len(documents)} documents after initial preprocessing\")\n",
    "\n",
    "freq = Counter(token for doc in documents for token in doc)\n",
    "top_n = {tok for tok, cnt in freq.most_common(50)}\n",
    "print(\"Top‐50 tokens to drop:\", top_n)\n",
    "stop_words |= top_n\n",
    "documents = [preprocess(\" \".join(doc)) for doc in documents]\n",
    "documents = [doc for doc in documents if len(doc) >= 5]\n",
    "print(f\"{len(documents)} docs remain after filtering top‐freq tokens\")\n",
    "\n",
    "bigram  = Phrases(documents, min_count=50, threshold=10)\n",
    "bigram_mod = Phraser(bigram)\n",
    "trigram = Phrases(bigram[documents], min_count=25, threshold=10)\n",
    "trigram_mod = Phraser(trigram)\n",
    "documents = [trigram_mod[bigram_mod[doc]] for doc in documents]\n",
    "\n",
    "dictionary = Dictionary(documents)\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.3)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "print(f\"Dictionary size after filtering: {len(dictionary)} tokens\")\n",
    "\n",
    "topic_nums = [14,17,20]\n",
    "passes = 15\n",
    "eval_every = 1\n",
    "workers = max(1, multiprocessing.cpu_count() - 1)\n",
    "coherence_scores = {}\n",
    "\n",
    "for k in topic_nums:\n",
    "    print(f\"\\nTraining LdaMulticore with k={k} topics…\")\n",
    "    lda = LdaMulticore(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=k,\n",
    "        passes=passes,\n",
    "        eval_every=eval_every,\n",
    "        workers=workers,\n",
    "        random_state=42,\n",
    "        alpha='asymmetric',\n",
    "        eta='auto'\n",
    "    )\n",
    "    cm = CoherenceModel(\n",
    "        model=lda,\n",
    "        texts=documents,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    score = cm.get_coherence()\n",
    "    coherence_scores[k] = score\n",
    "    print(f\"Coherence (c_v) = {score:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(list(coherence_scores.keys()), list(coherence_scores.values()), marker='o')\n",
    "plt.title(\"Coherence Score vs Number of Topics\")\n",
    "plt.xlabel(\"Topics\")\n",
    "plt.ylabel(\"Coherence (c_v)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "gen_k = 14\n",
    "print(f\"\\nrequired: k={gen_k} topics. Top words per topic:\")\n",
    "gen_lda = LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=gen_k,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every,\n",
    "    workers=workers,\n",
    "    random_state=42,\n",
    "    alpha='asymmetric',\n",
    "    eta='auto'\n",
    ")\n",
    "for idx, topic in gen_lda.show_topics(num_topics=gen_k, num_words=10, formatted=False):\n",
    "    print(f\"Topic {idx}: {', '.join([w for w,_ in topic])}\")\n",
    "\n",
    "topic_assignments = []\n",
    "for doc_bow in corpus:\n",
    "    topic_probs = gen_lda.get_document_topics(doc_bow)\n",
    "    dominant_topic = max(topic_probs, key=lambda x: x[1])[0] if topic_probs else -1\n",
    "    topic_assignments.append(dominant_topic)\n",
    "\n",
    "df_out = pd.DataFrame({\"text\": text_data, \"topic\": topic_assignments})\n",
    "output_path = \"data/clustered_petitions.parquet\"\n",
    "table = pa.Table.from_pandas(df_out)\n",
    "pq.write_table(table, output_path)\n",
    "print(f\"\\nSaved topic assignments to {output_path}\")\n",
    "\n",
    "topic_counts = Counter(topic_assignments)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(topic_counts.keys(), topic_counts.values())\n",
    "plt.xlabel(\"Topic Number\")\n",
    "plt.ylabel(\"Number of Documents\")\n",
    "plt.title(\"Distribution of Documents Across Topics\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
